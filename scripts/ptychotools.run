#!/usr/bin/env python
import argparse

from ptychotools.utils import io, log, parallel
from ptychotools.utils import ptypy_parameters as ptypy_params

from ptypy import utils as u
from ptypy.core import Ptycho


import socket

u.verbose.set_level(3)
parser = argparse.ArgumentParser(description='Runs a ptychography from the command line.')

parser.add_argument("config_file",
                    help="The path to the configuration file, can be yaml or json.",
                    type=str)

parser.add_argument('--output-folder', '-O',
                    dest="output_folder",
                    help="The path we want the outputs to exist in (will get created).",
                    type=str)

parser.add_argument('--ptypy-level', '-L',
                    dest="ptypy_level",
                    help="The level we want to run to ptypy to.",
                    default=5,
                    type=str)

parser.add_argument('--identifier', '-I',
                    dest="identifier",
                    help="This is the same as p.run.",
                    default=None,
                    nargs="+",
                    type=str)

parser.add_argument('--share-probe', '-S',
                    dest="share_probe",
                    action='store_true',
                    help="You can pass a list of scan identifiers and they will share the probe. "
                         "Assumes identical geometries for now since this is the dominant use case.")

parser.add_argument('--plot', '-P',
                    dest="plotting",
                    help="A switch for the plotting. 1: on, 0:off",
                    default=0,
                    type=int)

parser.add_argument('--gpu', '-G',
                    dest="use_gpu",
                    help="Using the GPU-accelerated version of ptypy",
                    action="store_true")

args = parser.parse_args()

args.identifier = args.identifier[0] if len(args.identifier)<2 else args.identifier


def get_parameters(args):
    if args.config_file.endswith(('.yml', '.yaml')):
        parameters_to_run = ptypy_params.paramtree_from_yaml(args.config_file)
    elif args.config_file.endswith(('.jsn', '.json')):
        parameters_to_run = ptypy_params.paramtree_from_json(args.config_file)
    else:
        raise RuntimeError("I don't recognise the file extension.")
    return parameters_to_run


if isinstance(args.identifier, list) and not args.share_probe:
    log(3, "%s" % args.identifier)
    log(3, 'RuntimeError: If you pass a list of arguments you must share the probe between them. Set -S option.')
    raise RuntimeError('If you pass a list of arguments you must share the probe between them. Set -S option.')


parameters = get_parameters(args)
parameters.run = io.get_common_id(args.identifier)


if args.plotting:
    log(3, "Turning the plotting on.")
    parameters.io.autoplot = u.Param(active=True)
    parameters.io.autoplot.threaded = False
    parameters.io.autoplot.interval = 1
    parameters.io.interaction = u.Param()
    parameters.io.interaction.server = u.Param()
    parameters.io.interaction.server.active = True
    if parallel.master:
        hn = {"hostname": socket.gethostbyname(socket.gethostname())}
    else:
        hn = None
    hn = parallel.comm.bcast(hn, root=0)
    port = 8985
    parameters.io.interaction.server.address = "tcp://"+hn['hostname']
    parameters.io.interaction.server.port = port
    parameters.io.interaction.server.connections = 1
    log(3, "Interaction is broadcast on host:%s:%s" % (hn['hostname'], port))
else:
    log(3, "Turning the plotting off.")
    parameters.io.autoplot = u.Param(active=False)

# make sure we aren't randomly writing somewhere if this isn't set.
if args.output_folder is not None:
    parameters.io.home = io.get_output_folder_name(args)
    run_name = io.get_common_id(parameters.run)
    parameters.io.rfile = "%s/scan_%s.ptyr" % (io.get_output_folder_name(args), run_name)
    parameters.io.autosave = u.Param(active=True, interval=100)
    log(3, "Autosave is on, with io going in {}, and the final reconstruction into {}".format(parameters.io.home,
                                                                                              parameters.io.rfile))
else:
    parameters.io.rfile = None
    parameters.io.autosave = u.Param(active=False)
    log(3, "Autosave is off. No output will be saved.")

# Replace engine with GPU-accelerated version (only works for DM right now)
if args.use_gpu:
    for id, engine in parameters.engines.items():
        if engine.name == "DM":
            engine.name = "DM_pycuda_stream"
            log(3, "Replacing the DM engine with the gpu-accelerated DM_pycuda_stream")
        else:
            log(3, "There is currently no gpu-acclerated version of the %s engine" %engine.name)
            
if args.share_probe:
    log(3, "Sharing the probe across scans: %s" % args.identifier)
    # need to duplicate the scans here but parse with different identifiers.
    if len(parameters.scans.keys())>1:
        log(3, "RuntimeError:For linked scans we should only have one scan listed in the json file.")
        raise RuntimeError("For linked scans we should only have one scan listed in the json file.")
    master_scan = parameters.scans[list(parameters.scans.keys())[0]]
    master_scan.data.dfile = "%s/scan_%s.ptyd" % (io.get_output_folder_name(args), run_name)
    del parameters.scans[list(parameters.scans.keys())[0]]  # delete it for now, we will add it back in with a different name
    for identifier in args.identifier:
        parameters.run = identifier
        parameters.scans[str(identifier)] = master_scan.copy(99)
        data_entry = parameters.scans[str(identifier)].data
        data_entry.dfile = "%s/scan_%s.ptyd" % (io.get_output_folder_name(args), str(parameters.run))
        for sub_entry_key, sub_entry in data_entry.items():
            if isinstance(sub_entry, dict):
                for dict_entry_key, dict_entry in sub_entry.items():
                    if isinstance(dict_entry, str):
                        sub_entry[dict_entry_key] = dict_entry % parameters
            elif isinstance(sub_entry, str):
                data_entry[sub_entry_key] = sub_entry % parameters

    print(args.identifier)

    # now run to level 3 to get the containers sorted
    P = Ptycho(parameters, level=3)
    probe_storages = list(P.probe.storages.values())
    master_storage = probe_storages[0]
    to_delete = []
    for sname, storage in P.probe.storages.items():
        for v in storage.views:
            v.storage = master_storage
            v.storageID = master_storage.ID
        if sname is not master_storage.ID:
            to_delete.append(sname)
    parallel.barrier()
    P.probe.reformat()  # deal with it!
    P.print_stats()
    parallel.barrier()
    #if parallel.master:
    for sname in set(to_delete):
        P.probe.storages.pop(sname) # delete its originally created storage
    parallel.barrier()
    P.init_engine()
    parallel.barrier()
    P.run()
    parallel.barrier()
    P.finalize()
else:
    # have to get the identifier into scan.data somehow.
    ptypy_params.parse_param_data_paths_with_paramtree(parameters, args)
    P = Ptycho(parameters, level=args.ptypy_level)

# now output the mapping compatible files
if parallel.master:
    log(3, "Converting to nexus files...")
    io.convert_ptyr_to_mapping(parameters.io.rfile, border=25)
    log(3, "Done.")

